{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSHlAbqzDFDq"
   },
   "source": [
    "# Fine-Tuning ChemBERTa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/seyonechithrananda/bert-loves-chemistry/blob/master/chemberta/examples/ZINC250K_Transfer_Learning_With_HuggingFace_tox21.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.45.2 # 4.46.0 makes pb\n",
    "# !pip install accelerate -U\n",
    "# !pip install -U datasets\n",
    "# !pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 19:44:19.336625: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 19:44:19.336680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 19:44:19.337653: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 19:44:19.343546: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 19:44:20.088216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "import datasets\n",
    "from datasets import load_from_disk\n",
    "# from datasets import load_metric\n",
    "# from evaluate import load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preamble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:    smiles\n",
      "Data type: comp\n",
      "Model:     DeepChem/ChemBERTa-5M-MTR\n"
     ]
    }
   ],
   "source": [
    "# 1. Choose your input mode: \"smiles\" or \"selfies\" whether to predict from SMILES or SELFIES\n",
    "\n",
    "INPUTS = \"smiles\" # \"smiles\", \"selfies\"\n",
    "\n",
    "# 2. Choose training on computed or experimental spectra\n",
    "DATA_TYPE = \"comp\" # [\"comp\", \"exp\"]\n",
    "\n",
    "# 3. Choose model\n",
    "# MODEL_NAME, INPUTS = \"ncfrey/ChemGPT-4.7M\", \"selfies\"    # for ChemGPT\n",
    "MODEL_NAME = \"DeepChem/ChemBERTa-5M-MTR\"                 # for SMILES / SELFIES\n",
    "# MODEL_NAME = \"seyonec/BPE_SELFIES_PubChem_shard00_160k\"  # for SELFIES\n",
    "MODEL_SUFFIX = MODEL_NAME.split(\"/\")[1]\n",
    "\n",
    "print(f\"Inputs:    {INPUTS}\")\n",
    "print(f\"Data type: {DATA_TYPE}\")\n",
    "print(f\"Model:     {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "args = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'output_activation': 'exp',\n",
    "    'norm_range': (50, 550),\n",
    "    'dropout': 0.2,\n",
    "    'activation': nn.ReLU(),\n",
    "    'ffn_num_layers': 0,          # 0, 1, 3, 5, 10\n",
    "    'ffn_hidden_dim': 2200,       # hidden dim of the FFN\n",
    "    'ffn_output_dim': 1801        # output dim of the FFN\n",
    "        }\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "NB_EPOCHS = 5         # 5, 10\n",
    "BATCH_SIZE = 64       # 16 for SELFIES due to OOM issues # 64 # cf. seyonechithrananda\n",
    "FINETUNING = False    # Whether to Finetune the model on experimental dataset or not\n",
    "LOADING_MODE = False  # Load an already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder: /storage/smiles2spec_models/smiles_comp_ChemBERTa-5M-MTR_FFNN-0-2200\n"
     ]
    }
   ],
   "source": [
    "ffn_num_layers = args[\"ffn_num_layers\"]\n",
    "ffn_hidden_dim = args[\"ffn_hidden_dim\"]\n",
    "\n",
    "MODEL_CACHE = \"/storage/smiles2spec_models\"\n",
    "SPECIFICATIONS = f\"{INPUTS}_{DATA_TYPE}_{MODEL_SUFFIX}_FFNN-{ffn_num_layers}-{ffn_hidden_dim}\"\n",
    "\n",
    "RESULTS_FOLDER = os.path.join(MODEL_CACHE, SPECIFICATIONS)\n",
    "print(f\"Results folder: {RESULTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATASET_FOLDER = \"/datasets\"\n",
    "DATASET_FOLDER = \"/storage/smiles2spec_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if INPUTS == \"selfies\":\n",
    "    MODE = \"with_selfies_\"\n",
    "elif INPUTS == \"smiles\":\n",
    "    MODE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the keep_in_memory=True, since the dataset folder is in read-only\n",
    "\n",
    "train_dataset = load_from_disk(os.path.join(DATASET_FOLDER, f\"train_{MODE}{DATA_TYPE}.hf\"), keep_in_memory=True)\n",
    "val_dataset = load_from_disk(os.path.join(DATASET_FOLDER, f\"val_{MODE}{DATA_TYPE}.hf\"), keep_in_memory=True)\n",
    "\n",
    "test_dataset_comp = load_from_disk(os.path.join(DATASET_FOLDER, f\"test_{MODE}comp.hf\"), keep_in_memory=True)\n",
    "test_dataset_exp = load_from_disk(os.path.join(DATASET_FOLDER, f\"test_{MODE}exp.hf\"), keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"spectrum\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"spectrum\", \"labels\")\n",
    "\n",
    "test_dataset_comp = test_dataset_comp.rename_column(\"spectrum\", \"labels\")\n",
    "test_dataset_exp = test_dataset_exp.rename_column(\"spectrum\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['smiles', 'labels'],\n",
       "     num_rows: 68404\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['base', 'shift', 'smiles', 'labels'],\n",
       "     num_rows: 6000\n",
       " }))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset_comp, test_dataset_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Models at https://huggingface.co/DeepChem\n",
    "#     or at https://huggingface.co/seyonec/ \n",
    "\n",
    "HF_TOKEN = \"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\" # your HF token\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=RESULTS_FOLDER) # for ChemBERTa\n",
    "\n",
    "if MODEL_NAME.startswith(\"ncfrey/ChemGPT\"):\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(batch, inputs_type=\"smiles\"):\n",
    "        \n",
    "    tokens = tokenizer(batch[inputs_type], \n",
    "                       truncation=True, \n",
    "                       padding=True, \n",
    "                       max_length=512)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b913dcceced4c60a1d66e95b1ab62a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c10fd6a1ce4e65b7b87c1bd115ef05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c658eb7e7e34c4bb46558ea82dd1053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aea001aeed24b868b74a6a7be2533a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, fn_kwargs={\"inputs_type\": INPUTS}, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, fn_kwargs={\"inputs_type\": INPUTS}, batched=True)\n",
    "\n",
    "test_dataset_comp = test_dataset_comp.map(tokenize, fn_kwargs={\"inputs_type\": INPUTS}, batched=True)\n",
    "test_dataset_exp = test_dataset_exp.map(tokenize, fn_kwargs={\"inputs_type\": INPUTS}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 68404\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['base', 'shift', 'smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 6000\n",
       " }))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset_comp, test_dataset_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "test_dataset_comp.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset_exp.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 68404\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 8551\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['base', 'shift', 'smiles', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 6000\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset_comp, test_dataset_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]COC(=O)c1ccc(NC(=O)Cn2c(-c3nnc(CC(C)C)o3)cc3ccccc32)cc1[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ncfrey/ChemGPT-4.7M', 'ChemGPT-4.7M')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME, MODEL_SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(train_dataset[0][\"labels\"])\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Smile2Spec(nn.Module):\n",
    "    \"\"\"A Smile2Spec model contains a LLM head, followed by a Feed Forward MLP.\"\"\"\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        Initializes the Smile2Spec model.\n",
    "        :param args: argument for building the model.\"\"\"\n",
    "\n",
    "        super(Smile2Spec, self).__init__()\n",
    "\n",
    "        # LLM\n",
    "        self.LLM = AutoModelForSequenceClassification.from_pretrained(args.get('model_name'))\n",
    "        \n",
    "        # Internal params\n",
    "        if \"ChemBERTa\" in args.get('model_name'): # my fix XXX\n",
    "            \n",
    "            input_dim = self.LLM.classifier.out_proj.out_features\n",
    "            \n",
    "        if \"ChemGPT\" in args.get('model_name'): # my fix XXX\n",
    "            \n",
    "            self.LLM.config.pad_token_id = self.LLM.config.eos_token_id\n",
    "            input_dim = self.LLM.score.out_features\n",
    "            \n",
    "        self.output_activation = args.get('output_activation')\n",
    "        self.norm_range = args.get('norm_range')\n",
    "\n",
    "        # FFN params\n",
    "        dropout = nn.Dropout(args.get('dropout'))\n",
    "        activation = args.get('activation')\n",
    "\n",
    "        # New classification head\n",
    "        # First layer        \n",
    "        if args.get('ffn_num_layers') == 0:\n",
    "            output_dim = args.get('ffn_output_dim')\n",
    "        else:\n",
    "            output_dim = args.get('ffn_hidden_dim')\n",
    "            \n",
    "        ffn = [activation, dropout, nn.Linear(input_dim, output_dim)]\n",
    "        \n",
    "        # Next layers\n",
    "        input_dim = args.get('ffn_hidden_dim')\n",
    "        output_dim = args.get('ffn_hidden_dim')\n",
    "        \n",
    "        for l in range(args.get('ffn_num_layers')):\n",
    "\n",
    "            if l == (args.get('ffn_num_layers') - 1):\n",
    "                output_dim = args.get('ffn_output_dim')\n",
    "                \n",
    "            ffn.extend([activation, dropout, nn.Linear(input_dim, output_dim)])\n",
    "            \n",
    "        self.ffn = nn.Sequential(*ffn)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids = None,\n",
    "                attention_mask = None,\n",
    "                labels=None):\n",
    "        \"\"\"\n",
    "        Runs the Smile2Spec model on input.\n",
    "        \n",
    "        :return: Output of the Smile2Spec model.\"\"\"\n",
    "\n",
    "        #Compute LLM output.\n",
    "        LLM_output = self.LLM(input_ids, \n",
    "                              attention_mask=attention_mask).logits # type: ignore\n",
    "\n",
    "        #Compute ffn output.\n",
    "        output = self.ffn(LLM_output)\n",
    "\n",
    "        # Positive value\n",
    "        if self.output_activation == 'exp':\n",
    "            output = torch.exp(output)\n",
    "        if self.output_activation == 'relu':\n",
    "            f = nn.ReLU()\n",
    "            output = f(output)\n",
    "\n",
    "        # Normalization\n",
    "        if self.norm_range is not None:\n",
    "            norm_data = output[:, self.norm_range[0]:self.norm_range[1]]\n",
    "            norm_sum = torch.sum(norm_data, 1)\n",
    "            norm_sum = torch.unsqueeze(norm_sum, 1)\n",
    "            output = torch.div(output, norm_sum)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# √ 1. oder of linear -> ReLU -> Dropout\n",
    "# √ 2. check other projecting dim!\n",
    "# √ 3. get projecting dim!\n",
    "# √ 4. Test learning for 0, 1, and 3\n",
    "# √ 5. Check the same for ChemGPT\n",
    "# √ 6. Modify .py file (args -> args_d, remove ffn_input_dim)\n",
    "# 7. push and run simuls\n",
    "\n",
    "\n",
    "# # MY ATTEMPT... DOES NOT WORK FOOR NOW!!!\n",
    "# # Modify the classifier module\n",
    "# class ModifiedRobertaClassificationHead(nn.Module):\n",
    "#     def __init__(self, args, original_classifier, num_layers=1):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.num_layers = num_layers\n",
    "        \n",
    "#         self.original_classifier = original_classifier\n",
    "#         if self.num_layers == 0:\n",
    "#             self.original_classifier.out_proj.out_features = args.get(\"ffn_output_dim\")\n",
    "#         else:\n",
    "#             self.original_classifier.out_proj.out_features = args.get(\"ffn_hidden_dim\")\n",
    "        \n",
    "        \n",
    "#         # Create a list to hold the layers\n",
    "#         layers = []\n",
    "#         # layers.append(nn.ReLU()) # WRONG!!!\n",
    "        \n",
    "#         # Add additional hidden layers based on num_layers\n",
    "#         for l in range(self.num_layers):\n",
    "#             if self.num_layers > 1 and l < self.num_layers - 1:\n",
    "#                 layers.append(self.original_classifier.dropout)\n",
    "#                 layers.append(nn.Linear(args.get(\"ffn_hidden_dim\"), args.get(\"ffn_hidden_dim\")))\n",
    "#             else:\n",
    "#                 layers.append(self.original_classifier.dropout)\n",
    "#                 layers.append(nn.Linear(args.get(\"ffn_hidden_dim\"), args.get(\"ffn_output_dim\")))\n",
    "#             layers.append(nn.ReLU())\n",
    "\n",
    "#         # Convert the list of layers to a Sequential model\n",
    "#         if self.num_layers > 0:\n",
    "#             self.extended_classifier = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.original_classifier(x)\n",
    "#         if self.num_layers > 0:\n",
    "#             x = self.extended_classifier(x) # XXX\n",
    "        \n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Smile2Spec(nn.Module):\n",
    "#     \"\"\"A Smile2Spec model contains a LLM head, followed by a Feed Forward MLP.\"\"\"\n",
    "    \n",
    "#     def __init__(self, args):\n",
    "#         \"\"\"\n",
    "#         Initializes the Smile2Spec model.\n",
    "#         :param args: argument for building the model.\"\"\"\n",
    "\n",
    "#         super(Smile2Spec, self).__init__()\n",
    "\n",
    "#         # # Create LLM head. # xxx old\n",
    "#         # self.LLM = AutoModelForSequenceClassification.from_pretrained(args.get('model_name'), \n",
    "#         #                                                               num_labels=args.get('ffn_output_dim'))\n",
    "        \n",
    "#         if args.get('model_name').startswith(\"ncfrey/ChemGPT\"): # xxx\n",
    "#             self.LLM.config.pad_token_id = self.LLM.config.eos_token_id\n",
    "        \n",
    "#         # Create output objects\n",
    "#         self.output_activation = args.get('output_activation')\n",
    "#         self.norm_range = args.get('norm_range')\n",
    "\n",
    "#         # Create FFN params\n",
    "#         dropout = nn.Dropout(args.get('dropout'))\n",
    "#         activation = args.get('activation')\n",
    "\n",
    "#         # Create LLM and FFN layers XXXXX\n",
    "#         if args.get('ffn_num_layers') == 0:\n",
    "#             num_labels = args.get('ffn_output_dim')\n",
    "#         else:\n",
    "#             num_labels = args.get('ffn_hidden_dim')\n",
    "        \n",
    "#         self.LLM = AutoModelForSequenceClassification.from_pretrained(args.get('model_name'), \n",
    "#                                                                       num_labels=num_labels)\n",
    "        \n",
    "#         # Replace the model's original classifier with the extended one\n",
    "#         new_classifier = ModifiedRobertaClassificationHead(args, self.LLM.classifier, \n",
    "#                                                            num_layers=args.get('ffn_num_layers'))\n",
    "#         self.LLM.classifier = new_classifier\n",
    "\n",
    "#     def forward(self,\n",
    "#                 input_ids = None,\n",
    "#                 attention_mask = None,\n",
    "#                 labels = None):\n",
    "#         \"\"\"\n",
    "#         Runs the Smile2Spec model on input.\n",
    "        \n",
    "#         :return: Output of the Smile2Spec model.\"\"\"\n",
    "\n",
    "#         # Compute LLM output\n",
    "#         output = self.LLM(input_ids, attention_mask=attention_mask).logits # type: ignore\n",
    "#         print(output.shape)\n",
    "\n",
    "# #         # Positive value mapping\n",
    "# #         if self.output_activation == 'exp':\n",
    "# #             output = torch.exp(output)\n",
    "            \n",
    "# #         if self.output_activation == 'ReLU':\n",
    "# #             f = nn.ReLU()\n",
    "# #             output = f(output)\n",
    "\n",
    "#         # Normalization mapping\n",
    "#         if self.norm_range is not None:\n",
    "#             # norm_data = output[:, self.norm_range[0]:self.norm_range[1]] # XXX\n",
    "#             norm_data = output[:, self.norm_range[0]:self.norm_range[1]]\n",
    "#             norm_sum = torch.sum(norm_data, 1)\n",
    "#             norm_sum = torch.unsqueeze(norm_sum, 1)\n",
    "#             # output = torch.div(output, norm_sum) # XXX\n",
    "#             output = torch.div(output, norm_sum)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SIDLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, model_spectra, target_spectra):\n",
    "\n",
    "        loss = torch.ones_like(target_spectra)\n",
    "\n",
    "        loss = torch.mul(torch.log(torch.div(model_spectra, target_spectra)), model_spectra) \\\n",
    "                + torch.mul(torch.log(torch.div(target_spectra, model_spectra)), target_spectra)\n",
    "        \n",
    "        loss = torch.sum(loss, dim=1)\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NB_EPOCHS = 5 # 10\n",
    "# BATCH_SIZE = 64 # 16 for SELFIES due to OOM issues # 64 # cf. seyonechithrananda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Model parameters\n",
    "\n",
    "# args = {\n",
    "#     'model_name': MODEL_NAME,\n",
    "#     'output_activation': 'exp',\n",
    "#     'norm_range': None, # (50, 550),\n",
    "#     'dropout': 0.2,\n",
    "#     'activation': nn.ReLU(),\n",
    "#     'ffn_num_layers': 1, # 0, 3\n",
    "#     'ffn_hidden_dim': 2200,      # hidden dim of the FFN\n",
    "#     'ffn_output_dim': 1801        # output dim of the FFN\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fec03eab6d4e86a0d801f0286ed63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b693964a854961b141b1fbf9b443b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/14.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-5M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Smile2Spec(\n",
       "  (LLM): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(600, 384, padding_idx=1)\n",
       "        (position_embeddings): Embedding(515, 384, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 384)\n",
       "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.144, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-2): 3 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.109, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.144, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=384, out_features=464, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=464, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.144, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (dropout): Dropout(p=0.144, inplace=False)\n",
       "      (out_proj): Linear(in_features=384, out_features=1801, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=1801, out_features=1801, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Smile2Spec(args)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params. :  6,749,457\n",
      "Total Trainable Params. :  6,749,457\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Total Params. : \", f\"{total_params:,}\")\n",
    "print(\"Total Trainable Params. : \", f\"{total_trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New loss will be implemented here\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "   \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        loss_fct = SIDLoss()\n",
    "        loss = loss_fct(outputs, labels)\n",
    "        \n",
    "        return (loss, {\"label\": outputs}) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=5e-5, #2e-5,                # cf. seyonechithrananda / cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    # eval\n",
    "    eval_strategy=\"steps\",                    # cf. paper Sun et al.\n",
    "    eval_steps=400,                           # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=RESULTS_FOLDER+'logs',  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=400,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    save_steps=400,                           # save model at every eval (default 500)\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    metric_for_best_model='eval_loss',\n",
    "    # metric_for_best_model='mse', # XXX\n",
    "    \n",
    "    report_to=\"none\",                         # \"wandb\" or \"none\" to turn wandb off!\n",
    "    # run_name=f\"{model_suffix}\",               # name of the W&B run (optional)\n",
    "\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-07 19:52:26,628] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x199 and 1801x1801)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m SIDLoss()\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fct(outputs, labels)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 67\u001b[0m, in \u001b[0;36mSmile2Spec.forward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     63\u001b[0m LLM_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLLM(input_ids, \n\u001b[1;32m     64\u001b[0m                       attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\u001b[38;5;241m.\u001b[39mlogits \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#Compute ffn output.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLLM_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Positive value\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_activation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x199 and 1801x1801)"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "results = trainer.train()\n",
    "\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save history (loss), trainable params, training time\n",
    "\n",
    "with open(os.path.join(RESULTS_FOLDER, \"log_history.pkl\"), \"wb\") as fh:\n",
    "\n",
    "    pickle.dump(trainer.state.log_history, fh)\n",
    "    \n",
    "    \n",
    "with open(os.path.join(RESULTS_FOLDER, \"training_time.pkl\"), \"wb\") as fh:\n",
    "\n",
    "    pickle.dump(training_time, fh)\n",
    "    \n",
    "\n",
    "with open(os.path.join(RESULTS_FOLDER, \"nb_parameters.pkl\"), \"wb\") as fh:\n",
    "    \n",
    "    params = {\"total_params\": total_params, \"total_trainable_params\" : total_trainable_params}\n",
    "    \n",
    "    pickle.dump(params, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.save_model(RESULTS_FOLDER)\n",
    "\n",
    "torch.save(model.state_dict(), RESULTS_FOLDER + \"/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove checkpoints since best model saved (saves space)\n",
    "\n",
    "dirs = os.listdir(RESULTS_FOLDER)\n",
    "dirs = [d for d in dirs if d.startswith(\"checkpoint\")] # checkpoints dirs\n",
    "\n",
    "for d in dirs:\n",
    "    shutil.rmtree(os.path.join(RESULTS_FOLDER, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine-Tune (if needed, depends on the task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FINETUNING = False # Whether to Finetune the model on experimental dataset or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine tune on experimental\n",
    "\n",
    "if FINETUNING:\n",
    "    \n",
    "    #Load dataset\n",
    "    train_dataset_exp = load_from_disk(os.path.join(DATASET_FOLDER, \"train_exp\"), keep_in_memory=True)\n",
    "    val_dataset_exp = load_from_disk(os.path.join(DATASET_FOLDER, \"val_exp\"), keep_in_memory=True)\n",
    "    \n",
    "    #Preprocess Dataset\n",
    "    train_dataset_exp = train_dataset_exp.rename_column(\"spectrum\", \"labels\")\n",
    "    val_dataset_exp = val_dataset_exp.rename_column(\"spectrum\", \"labels\")\n",
    "    \n",
    "    train_dataset_exp = train_dataset_exp.map(tokenize, batched=True)\n",
    "    val_dataset_exp = val_dataset_exp.map(tokenize, batched=True)\n",
    "    \n",
    "    train_dataset_exp.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    val_dataset_exp.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if FINETUNING:\n",
    "    \n",
    "    training_args_exp = TrainingArguments(\n",
    "        \n",
    "        # output\n",
    "        output_dir=f\"/storage/smiles2spec_models/exp/{MODEL_SUFFIX}\",          \n",
    "        \n",
    "        # params\n",
    "        num_train_epochs=NB_EPOCHS // 2,               # nb of epochs\n",
    "        per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "        per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "        learning_rate=5e-5, #2e-5,                # cf. seyonechithrananda / cf. paper Sun et al.\n",
    "    #     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "        warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "        weight_decay=0.01,                        # strength of weight decay\n",
    "        \n",
    "        # eval\n",
    "        evaluation_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "        eval_steps=200,                           # cf. paper Sun et al.\n",
    "        \n",
    "        # log\n",
    "        logging_dir=f\"/storage/smiles2spec_models/exp/{MODEL_SUFFIX}\"+'logs',  \n",
    "        logging_strategy='steps',\n",
    "        logging_steps=200,\n",
    "        \n",
    "        # save\n",
    "        save_strategy='steps',\n",
    "        save_total_limit=2,\n",
    "        save_steps=200,                           # save model at every eval (default 500)\n",
    "        load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "        metric_for_best_model='eval_loss',\n",
    "        # metric_for_best_model='mse', # XXX\n",
    "        \n",
    "        report_to=\"none\",                         # \"wandb\" or \"none\" to turn wandb off!\n",
    "        # run_name=f\"{model_suffix}\",               # name of the W&B run (option   al)\n",
    "\n",
    "        remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if FINETUNING:\n",
    "    \n",
    "    trainer_exp = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args_exp,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset_exp,\n",
    "        eval_dataset=val_dataset_exp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if FINETUNING:\n",
    "    \n",
    "    trainer_exp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model and results if already trained and evaluated\n",
    "\n",
    "# LOADING_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute predictions\n",
    "\n",
    "predicts_comp = trainer.predict(test_dataset_comp)\n",
    "predicts_exp = trainer.predict(test_dataset_exp)\n",
    "\n",
    "test_preds_comp, test_truths_comp = predicts_comp.predictions, predicts_comp.label_ids\n",
    "test_preds_exp, test_truths_exp = predicts_exp.predictions, predicts_exp.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model if necessary XXX need to plug the weights!!!!!!!\n",
    "\n",
    "if LOADING_MODE:\n",
    "\n",
    "    args = {\n",
    "        'model_name': MODEL_NAME,\n",
    "        'output_activation': 'exp',\n",
    "        'norm_range': None, # (50, 550),\n",
    "        'dropout': 0.2,\n",
    "        'activation': nn.ReLU(),\n",
    "        'ffn_num_layers': 1, # 3,\n",
    "        'ffn_hidden_dim': 2200,\n",
    "        'ffn_output_dim': 1801\n",
    "        }\n",
    "\n",
    "\n",
    "    model = Smile2Spec(args)\n",
    "    \n",
    "    model_state_dict = torch.load(os.path.join(RESULTS_FOLDER, \"model.pt\"))\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "    \n",
    "    print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds_comp.shape, test_truths_comp.shape, test_preds_exp.shape, test_truths_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save results (if not in loading mode)\n",
    "\n",
    "if not LOADING_MODE:\n",
    "    \n",
    "    torch.save(test_preds_comp, os.path.join(RESULTS_FOLDER,'test_preds_comp.pt'))\n",
    "    torch.save(test_truths_comp, os.path.join(RESULTS_FOLDER,'test_truths_comp.pt'))\n",
    "\n",
    "    torch.save(test_preds_exp, os.path.join(RESULTS_FOLDER,'test_preds_exp.pt'))\n",
    "    torch.save(test_truths_exp, os.path.join(RESULTS_FOLDER,'test_truths_exp.pt'))\n",
    "    \n",
    "    print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load results if necessary\n",
    "if LOADING_MODE:\n",
    "    \n",
    "    test_preds_comp = torch.load(os.path.join(RESULTS_FOLDER,'test_preds_comp.pt'))\n",
    "    test_truths_comp = torch.load(os.path.join(RESULTS_FOLDER,'test_truths_comp.pt'))\n",
    "\n",
    "    test_preds_exp = torch.load(os.path.join(RESULTS_FOLDER,'test_preds_exp.pt'))\n",
    "    test_truths_exp = torch.load(os.path.join(RESULTS_FOLDER,'test_truths_exp.pt'))\n",
    "    \n",
    "    print(\"Predictions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SISScore(predicted_spectrum, true_spectrum):\n",
    "\n",
    "    # Gaussian Convolution\n",
    "    predicted_spectrum_conv = gaussian_filter1d(predicted_spectrum, 5)\n",
    "    true_spectrum_conv = gaussian_filter1d(true_spectrum, 5)\n",
    "\n",
    "    # Normalization\n",
    "    predicted_spectrum_conv = nn.functional.normalize(torch.tensor(predicted_spectrum_conv).reshape(1, -1), p=1)\n",
    "    true_spectrum_conv = nn.functional.normalize(torch.tensor(true_spectrum_conv).reshape(1, -1), p=1)\n",
    "    \n",
    "    # Initialize SID Class\n",
    "    SID = SIDLoss()\n",
    "    \n",
    "    sid = SID(predicted_spectrum_conv, true_spectrum_conv)\n",
    "\n",
    "    return 1/(1+sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in np.random.choice(8551, 5):\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    spectrum_truth = test_truths_comp[i, :]\n",
    "    spectrum_pred = test_preds_comp[i, :]\n",
    "    spectrum_pred_smooth = gaussian_filter1d(spectrum_pred, 5) # plot smoothed predictions if preferred\n",
    "\n",
    "    sis_score = SISScore(spectrum_pred, spectrum_truth)\n",
    "\n",
    "    plt.plot(range(len(spectrum_truth)), spectrum_truth, label=\"true spectrum\", alpha=0.5)\n",
    "    plt.plot(range(len(spectrum_pred)), spectrum_pred, label=f\"predicted spectrum \\nSIS Score : {sis_score:.2f}\", alpha=0.5)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in np.random.choice(6000, 5):\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    spectrum_truth = test_truths_exp[i, :]\n",
    "    spectrum_pred = test_preds_exp[i, :]\n",
    "    spectrum_pred_smooth = gaussian_filter1d(spectrum_pred, 5) # plot smoothed predictions if preferred\n",
    "    \n",
    "    sis_score = SISScore(spectrum_pred, spectrum_truth)\n",
    "\n",
    "    plt.plot(range(len(spectrum_truth)), spectrum_truth, label=\"true spectrum\", alpha=0.5)\n",
    "\n",
    "    plt.plot(range(len(spectrum_pred)), spectrum_pred, label=f\"predicted spectrum \\nSIS Score : {sis_score:.2f}\", alpha=0.5)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051d193cd87f47c1971fb87544e1e615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d7247c119e642c5894f15ca6974ef3e",
       "IPY_MODEL_a79c22bb34ec4f698a00752b47a6f631",
       "IPY_MODEL_d95f3a3f26c6470d984542cdfd68bec1"
      ],
      "layout": "IPY_MODEL_343e11c62a59448eb43bbc0c31bf5f11"
     }
    },
    "0e0a20b5ed7a44e9834022e7eba2194d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8eda8bfe08e4152a80c63830138c96d",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f258eacd6d0472385d41523b65dea8b",
      "value": 2
     }
    },
    "130120644beb48acbc038651459af43c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1af01f1f1aac42b8bff46fe4df8a59ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eee8731f316244eda5ff0765fd12bf85",
       "IPY_MODEL_f135278e410f4b708435bb80fb630bcf",
       "IPY_MODEL_2e6fc79bf5c149d6b0bc5c52e18debc7"
      ],
      "layout": "IPY_MODEL_a4b0debc025444a59abd6953b3512c0d"
     }
    },
    "1b6c59a51359453c926bfcddb3d0f0ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ca492fddbaa4ea7a3226649154e01fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f258eacd6d0472385d41523b65dea8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f73f8b4d4da4e74adc135f2a2f6ee65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b6c59a51359453c926bfcddb3d0f0ea",
      "placeholder": "​",
      "style": "IPY_MODEL_dac3669f18284161a58d52f26dffb761",
      "value": "pytorch_model-00002-of-00002.bin: 100%"
     }
    },
    "20670478612f4b1a8a5f23d71a2609a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "228b1bcf604f454f8060a250b58008a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27bb18a199ca47108c7a61e9c443de36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bb3d36d248a48fba364f14d9e840306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e6fc79bf5c149d6b0bc5c52e18debc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b29647e268414329be56047e522e28b9",
      "placeholder": "​",
      "style": "IPY_MODEL_27bb18a199ca47108c7a61e9c443de36",
      "value": " 9.98G/9.98G [06:35&lt;00:00, 25.8MB/s]"
     }
    },
    "33ebb868f3e846f6af1a1a2a8ad6a3cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f73f8b4d4da4e74adc135f2a2f6ee65",
       "IPY_MODEL_68da6e6e69c8419895bea2068760534e",
       "IPY_MODEL_6dc1a868e08c4c3b8315116d2c46573b"
      ],
      "layout": "IPY_MODEL_7a5d714c17374104bb6f5caaa5541c10"
     }
    },
    "343e11c62a59448eb43bbc0c31bf5f11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52c4bf7418f74bc79a8c12fe35901974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5e609d111b34d408a53a4cd71bb43d5",
       "IPY_MODEL_0e0a20b5ed7a44e9834022e7eba2194d",
       "IPY_MODEL_b5627331e78e4eb28765ed20f32cf403"
      ],
      "layout": "IPY_MODEL_8084d4cb267f4a52b3d80ec34d291190"
     }
    },
    "68da6e6e69c8419895bea2068760534e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3511f489f6d47cc8d404ab6f367b29f",
      "max": 3500316627,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20670478612f4b1a8a5f23d71a2609a7",
      "value": 3500316627
     }
    },
    "6aef866a6c474dfabb2140ded933c5aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc1a868e08c4c3b8315116d2c46573b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b463153ec04749e38540389efa2981f7",
      "placeholder": "​",
      "style": "IPY_MODEL_2bb3d36d248a48fba364f14d9e840306",
      "value": " 3.50G/3.50G [02:27&lt;00:00, 26.4MB/s]"
     }
    },
    "7a1f3340688d408092adade75f4baac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a5d714c17374104bb6f5caaa5541c10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8084d4cb267f4a52b3d80ec34d291190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84da055d24694320843e13ad37438792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c887ca9b0eb44fdb8608bf36b5db5c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90b281e9c5ed4e77ab93e5879d0b15a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9434350b1b9c4060812feb9ecbf63278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95501d0b5a22407288f008bf8cc69726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d7247c119e642c5894f15ca6974ef3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a153c96bd1fe4c48a41e9b9c7c00dd6e",
      "placeholder": "​",
      "style": "IPY_MODEL_84da055d24694320843e13ad37438792",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "a153c96bd1fe4c48a41e9b9c7c00dd6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3511f489f6d47cc8d404ab6f367b29f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4b0debc025444a59abd6953b3512c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79c22bb34ec4f698a00752b47a6f631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e375632975904402baea46163e2eeca1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95501d0b5a22407288f008bf8cc69726",
      "value": 2
     }
    },
    "a8dcdf1f7ab64242acb057e8b54ebf79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8eda8bfe08e4152a80c63830138c96d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b29647e268414329be56047e522e28b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b463153ec04749e38540389efa2981f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5627331e78e4eb28765ed20f32cf403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_228b1bcf604f454f8060a250b58008a1",
      "placeholder": "​",
      "style": "IPY_MODEL_90b281e9c5ed4e77ab93e5879d0b15a3",
      "value": " 2/2 [01:13&lt;00:00, 33.04s/it]"
     }
    },
    "b6e821c974674f2290c354238d6c919c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf722f71c61b4285bcbbf32fd619b3a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c887ca9b0eb44fdb8608bf36b5db5c5",
      "placeholder": "​",
      "style": "IPY_MODEL_e4698337e6b843afac706ab657ca6af9",
      "value": " 2/2 [06:36&lt;00:00, 396.47s/it]"
     }
    },
    "bf77e97593a349718bdb5fd9bfd28fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3a4fedc73b3480089ef9d13381471ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eeba50e8242c4753bfc0ea48e03f9078",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a1f3340688d408092adade75f4baac4",
      "value": 2
     }
    },
    "c5e609d111b34d408a53a4cd71bb43d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8dcdf1f7ab64242acb057e8b54ebf79",
      "placeholder": "​",
      "style": "IPY_MODEL_1ca492fddbaa4ea7a3226649154e01fd",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c99aff4cfd664ae8a165a27bea0566c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4b64cab6b7b418c8a2575ee26839039",
       "IPY_MODEL_c3a4fedc73b3480089ef9d13381471ed",
       "IPY_MODEL_bf722f71c61b4285bcbbf32fd619b3a6"
      ],
      "layout": "IPY_MODEL_fd11a6148b704c5b9142c5e8de2d3b25"
     }
    },
    "d66fa096d442423c9447cbfbdc1aad8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d95f3a3f26c6470d984542cdfd68bec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6aef866a6c474dfabb2140ded933c5aa",
      "placeholder": "​",
      "style": "IPY_MODEL_d66fa096d442423c9447cbfbdc1aad8d",
      "value": " 2/2 [00:59&lt;00:00, 27.43s/it]"
     }
    },
    "dac3669f18284161a58d52f26dffb761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e375632975904402baea46163e2eeca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4698337e6b843afac706ab657ca6af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4b64cab6b7b418c8a2575ee26839039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0bcdaf940d14ad796fc7ac46c8e1e64",
      "placeholder": "​",
      "style": "IPY_MODEL_b6e821c974674f2290c354238d6c919c",
      "value": "Upload 2 LFS files: 100%"
     }
    },
    "eeba50e8242c4753bfc0ea48e03f9078": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eee8731f316244eda5ff0765fd12bf85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_130120644beb48acbc038651459af43c",
      "placeholder": "​",
      "style": "IPY_MODEL_bf77e97593a349718bdb5fd9bfd28fe3",
      "value": "pytorch_model-00001-of-00002.bin: 100%"
     }
    },
    "f0bcdaf940d14ad796fc7ac46c8e1e64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f135278e410f4b708435bb80fb630bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7292741953e47699540ef8712fc0d8d",
      "max": 9976637886,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9434350b1b9c4060812feb9ecbf63278",
      "value": 9976637886
     }
    },
    "f7292741953e47699540ef8712fc0d8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd11a6148b704c5b9142c5e8de2d3b25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
